# PDF Q&A Bot

RAG-based document question-answering app with:

- **Frontend**: React app (`frontend/`)
- **Backend API**: Node + Express (`server.js`)
- **RAG Service**: FastAPI + Hugging Face + FAISS (`rag-service/`)

Upload a PDF, ask questions from its content, and generate a short summary. You can export the chat as **CSV** or **TXT** (plain text).

---

## üöÄ Important: Context Leakage Fix Implemented

**Issue Resolved**: The system previously showed content from old PDFs when answering questions about new PDFs. This has been **completely fixed**.

**For testing and understanding the fix**, see:
- üìñ [START_HERE.md](START_HERE.md) - Quick start (5 minutes)
- üß™ [QUICK_TEST_GUIDE.md](QUICK_TEST_GUIDE.md) - Testing procedures
- üìã [CONTEXT_LEAKAGE_FIX.md](CONTEXT_LEAKAGE_FIX.md) - Technical details
- üìù [SOLUTION_SUMMARY.md](SOLUTION_SUMMARY.md) - Complete overview

---

## Architecture

1. Frontend uploads file to Node backend (`/upload`)
2. Node forwards file path to FastAPI (`/process-pdf`)
3. FastAPI detects file format (`.pdf`, `.docx`, `.txt`, `.md`), loads and splits the document, builds vector index with embeddings
4. For `/ask` and `/summarize`, FastAPI retrieves relevant chunks and generates output with a Hugging Face model

## Project Structure

```text
.
‚îú‚îÄ‚îÄ frontend/           # React UI
‚îú‚îÄ‚îÄ rag-service/        # FastAPI RAG service
‚îú‚îÄ‚îÄ server.js           # Node API gateway
‚îú‚îÄ‚îÄ uploads/            # Uploaded files (runtime)
‚îî‚îÄ‚îÄ CONTRIBUTING.md
```

## Prerequisites

- Node.js 18+ (LTS recommended)
- Python 3.10+
- `pip`

## 1) Clone and Install Dependencies

From repository root:

```bash
npm install
cd frontend && npm install
cd ../rag-service && python -m pip install -r requirements.txt
```

## 2) Environment Variables

Create `.env` in repo root (or edit existing):

```env
# Optional model override
HF_GENERATION_MODEL=google/flan-t5-base
```

Notes:

- `OPENAI_API_KEY` is not required for current Hugging Face RAG flow.
- Keep real secrets out of git.

## 3) Run the App (3 terminals)

### Terminal A ‚Äî RAG service (port 5000)

```bash
cd rag-service
uvicorn main:app --host 0.0.0.0 --port 5000 --reload
```

### Terminal B ‚Äî Node backend (port 4000)

```bash
# from the repository root (where server.js lives)
cd <your-repo-directory>
node server.js
```

### Terminal C ‚Äî Frontend (port 3000)

```bash
# navigate into the frontend subfolder from the repo root
cd frontend
npm start
```

Open: `http://localhost:3000`

## API Endpoints

Node backend (`http://localhost:4000`):

- `POST /upload` (multipart form-data, field: `file`) ‚Äî accepts `.pdf`, `.docx`, `.txt`, `.md`
- `POST /ask` (`{ "question": "..." }`)
- `POST /summarize` (`{}`)

FastAPI RAG service (`http://localhost:5000`):

- `POST /process-pdf`
- `POST /ask`
- `POST /summarize`

Interactive docs: `http://localhost:5000/docs`

## Troubleshooting

- **`Cannot POST /upload` from frontend**
	- Restart frontend dev server after config changes: `npm start`
	- Ensure Node backend is running on port `4000`

- **Upload fails / connection refused**
	- Ensure FastAPI is running on port `5000`

- **Slow first request**
	- Hugging Face model downloads on first run (can take time)

- **Port already in use**
	- Stop old processes or change ports consistently in frontend/backend/service

## Development Notes

- RAG index is in-memory (rebuilds after restart)
- Summarization and QA use retrieved context from the last processed PDF

## Advanced Issues

See [ADVANCED_ISSUES.md](ADVANCED_ISSUES.md) for critical security, performance, and architecture issues that need attention before production deployment.

## Contributing

Refer to [CONTRIBUTING.md](CONTRIBUTING.md) for detailed instructions on creating a branch, naming conventions, committing changes, and submitting pull requests.
